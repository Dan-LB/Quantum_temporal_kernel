{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dtaidistance import dtw\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import random\n",
    "\n",
    "from SVM_models.models import evaluate_binary_SVM_standard, evaluate_binary_SVM_custom\n",
    "\n",
    "# import GunPoint dataset from GunPoint/GunPoint_test.txt and GunPoint/GunPoint_train.txt\n",
    "\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    with open(file_path) as f:\n",
    "        lines = f.readlines()\n",
    "    # Parse each line, separating the label and features\n",
    "    labels = []\n",
    "    features = []\n",
    "    for line in lines:\n",
    "        values = list(map(float, line.strip().split()))\n",
    "        labels.append(int(values[0])-1)  # First value is the label, cast to int\n",
    "        features.append(values[1:])    # Remaining values are features\n",
    "    # Convert lists to numpy arrays for easier handling\n",
    "    labels = np.array(labels)\n",
    "    features = np.array(features)\n",
    "    # normalize dataset to 0 1\n",
    "    features = (features - features.min()) / (features.max() - features.min())\n",
    "    return labels, features\n",
    "\n",
    "# Load the GunPoint dataset\n",
    "train_labels, train_features = load_dataset(\"GunPoint/GunPoint_train.txt\")\n",
    "test_labels, test_features = load_dataset(\"GunPoint/GunPoint_test.txt\")\n",
    "\n",
    "# split test in validation (50) and test (100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPS = [\n",
    "    \"RANDOM\",\n",
    "    \"RANDOM_BEST\",\n",
    "    \"BAYESIAN_HAMILTONIAN\",\n",
    "    \"BAYESIAN_MODEL\",\n",
    "]\n",
    "\n",
    "OPT_TIMES = 30\n",
    "\n",
    "CONFIG = {\n",
    "    \"N_QUBITS\": 2,\n",
    "    \"SPARSITY\": 0.95,\n",
    "    \"ENCODING\": \"euler\",\n",
    "}\n",
    "\n",
    "SEEDS = range(10)\n",
    "EXP = \"RANDOM\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def save_results(EXP, encoding, seed, train_accuracy, val_accuracy, test_accuracy, Hamiltonian_c, hidden_alphas):\n",
    "    # Create folder structure\n",
    "    folder_name = f\"{EXP}__{encoding}\"\n",
    "    seed_folder = os.path.join(\"exps_results\", folder_name, f\"exp_{seed}\")\n",
    "    os.makedirs(seed_folder, exist_ok=True)\n",
    "\n",
    "    # Save configuration and OPT_TIMES to a text file\n",
    "    with open(os.path.join(seed_folder, \"config.txt\"), \"w\") as f:\n",
    "        f.write(f\"Experiment: {EXP}\\n\")\n",
    "        f.write(f\"Encoding: {encoding}\\n\")\n",
    "        f.write(f\"Number of Qubits: {CONFIG['N_QUBITS']}\\n\")\n",
    "        f.write(f\"Sparsity Coefficient: {CONFIG['SPARSITY']}\\n\")\n",
    "        f.write(f\"OPT_TIMES: {OPT_TIMES}\\n\")\n",
    "\n",
    "    # Save train, validation, and test accuracy\n",
    "    with open(os.path.join(seed_folder, \"train_accuracy.txt\"), \"w\") as f:\n",
    "        f.write(f\"Train Accuracy: {train_accuracy}\\n\")\n",
    "    \n",
    "    with open(os.path.join(seed_folder, \"val_accuracy.txt\"), \"w\") as f:\n",
    "        f.write(f\"Validation Accuracy: {val_accuracy}\\n\")\n",
    "\n",
    "    with open(os.path.join(seed_folder, \"test_accuracy.txt\"), \"w\") as f:\n",
    "        f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "\n",
    "    # Save Hamiltonian_c and hidden_alphas\n",
    "    with open(os.path.join(seed_folder, \"Hamiltonian_c.txt\"), \"w\") as f:\n",
    "        f.write(str(Hamiltonian_c))\n",
    "\n",
    "    with open(os.path.join(seed_folder, \"hidden_alphas.txt\"), \"w\") as f:\n",
    "        f.write(str(hidden_alphas))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SVM_models.QuantumSVM import QuantumSVM\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating random coefficients for the Hamiltonian...\n",
      "\n",
      "Generating random alphas...\n",
      "Non-zero alphas: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building TRAIN_KERNEL: 100%|██████████| 1225/1225 [01:03<00:00, 19.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building TEST_KERNEL: 100%|██████████| 2500/2500 [02:04<00:00, 20.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building TEST_KERNEL:  61%|██████    | 3040/5000 [09:40<06:00,  5.44it/s] "
     ]
    }
   ],
   "source": [
    "for SEED in SEEDS:\n",
    "    test_labels, val_labels, test_features, val_features = train_test_split(test_labels, test_features, test_size=0.33, random_state=SEED)\n",
    "\n",
    "    quantum_svm = QuantumSVM(n_qubits=CONFIG[\"N_QUBITS\"], sparsity_coefficient=CONFIG[\"SPARSITY\"], embedding_code=CONFIG[\"ENCODING\"])\n",
    "\n",
    "    quantum_svm.fit(train_features, train_labels)\n",
    "    y_train = quantum_svm.predict_on_train()\n",
    "    train_accuracy = accuracy_score(train_labels, y_train)\n",
    "    print(f\"Train Accuracy: {train_accuracy}\")\n",
    "\n",
    "    y_val = quantum_svm.predict(val_features)\n",
    "    val_accuracy = accuracy_score(val_labels, y_val)\n",
    "    print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "\n",
    "    y_test = quantum_svm.predict(test_features)\n",
    "    accuracy = accuracy_score(test_labels, y_test)\n",
    "    print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "    # now I want to save the model Hamiltonian_c and hidden_alphas\n",
    "    print(\"Saving model...\")\n",
    "    Hamiltonian_c = quantum_svm.Hamiltonian_c\n",
    "    hidden_alphas = quantum_svm.hidden_alphas\n",
    "\n",
    "    print(\"Hamiltonian_c: \", Hamiltonian_c)\n",
    "    print(\"hidden_alphas: \", hidden_alphas)\n",
    "\n",
    "    save_results(EXP, CONFIG[\"ENCODING\"], SEED, train_accuracy, val_accuracy, accuracy, Hamiltonian_c, hidden_alphas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QtKernel_x_AD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
