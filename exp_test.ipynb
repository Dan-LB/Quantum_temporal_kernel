{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dtaidistance import dtw\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "from SVM_models.models import evaluate_binary_SVM_standard, evaluate_binary_SVM_custom\n",
    "\n",
    "# import GunPoint dataset from GunPoint/GunPoint_test.txt and GunPoint/GunPoint_train.txt\n",
    "\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    with open(file_path) as f:\n",
    "        lines = f.readlines()\n",
    "    # Parse each line, separating the label and features\n",
    "    labels = []\n",
    "    features = []\n",
    "    for line in lines:\n",
    "        values = list(map(float, line.strip().split()))\n",
    "        labels.append(int(values[0])-1)  # First value is the label, cast to int\n",
    "        features.append(values[1:])    # Remaining values are features\n",
    "    # Convert lists to numpy arrays for easier handling\n",
    "    labels = np.array(labels)\n",
    "    features = np.array(features)\n",
    "    # normalize dataset to 0 1\n",
    "    features = (features - features.min()) / (features.max() - features.min())\n",
    "    return labels, features\n",
    "\n",
    "# Load the GunPoint dataset\n",
    "\n",
    "#dataset_path with join\n",
    "\n",
    "train_path = os.path.join(\"GunPoint\", \"GunPoint_TRAIN.txt\")\n",
    "test_path = os.path.join(\"GunPoint\", \"GunPoint_TEST.txt\")\n",
    "\n",
    "train_labels, train_features = load_dataset(train_path)\n",
    "INITIAL_TEST_LABELS, INITIAL_TEST_FEATURES = load_dataset(test_path)\n",
    "\n",
    "# split test in validation (50) and test (100)\n",
    "SEED = 0\n",
    "test_labels, val_labels, test_features, val_features = train_test_split(INITIAL_TEST_LABELS, INITIAL_TEST_FEATURES, test_size=0.33, random_state=SEED)\n",
    "\n",
    "# for r = r, reduce all the sets to 20% of the original size\n",
    "\n",
    "r = .5\n",
    "\n",
    "train_labels = train_labels[:int(r*len(train_labels))]\n",
    "train_features = train_features[:int(r*len(train_features))]\n",
    "test_labels = test_labels[:int(r*len(test_labels))]\n",
    "test_features = test_features[:int(r*len(test_features))]\n",
    "val_labels = val_labels[:int(r*len(val_labels))]\n",
    "val_features = val_features[:int(r*len(val_features))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating random coefficients for the Hamiltonian...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [05:01<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_train_dict generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [17:19<00:00,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_test_dict generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from Quantum_temporal_kernel.SVM_models.QuantumSVM_2 import QuantumSVM\n",
    "quantum_svm = QuantumSVM(n_qubits=2)\n",
    "quantum_svm.compute_kernels(train_features, test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "base_learner = SVC(C=100)\n",
    "from MKLpy.algorithms import EasyMKL, AverageMKL\n",
    "\n",
    "#KLtr must be a list of kernels from the dictionary kernels_train\n",
    "\n",
    "#convert the dictionary to a list\n",
    "KLtr = []\n",
    "for key in quantum_svm.K_train_dict:\n",
    "    KLtr.append(quantum_svm.K_train_dict[key])\n",
    "Ytr = train_labels\n",
    "\n",
    "KLte = []\n",
    "for key in quantum_svm.K_test_dict:\n",
    "    KLte.append(quantum_svm.K_test_dict[key])\n",
    "Yte = test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8200, roc AUC score: 0.9040\n"
     ]
    }
   ],
   "source": [
    "mkl = AverageMKL().fit(KLtr, Ytr)       #combine kernels and train the classifier\n",
    "y_preds  = mkl.predict(KLte)            #predict the output class\n",
    "y_scores = mkl.decision_function(KLte) \n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "accuracy = accuracy_score(Yte, y_preds)\n",
    "roc_auc = roc_auc_score(Yte, y_scores)\n",
    "print ('Accuracy score: %.4f, roc AUC score: %.4f' % (accuracy, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7200, roc AUC score: 0.8848\n"
     ]
    }
   ],
   "source": [
    "mkl = EasyMKL().fit(KLtr, Ytr)       #combine kernels and train the classifier\n",
    "y_preds  = mkl.predict(KLte)            #predict the output class\n",
    "y_scores = mkl.decision_function(KLte) \n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "accuracy = accuracy_score(Yte, y_preds)\n",
    "roc_auc = roc_auc_score(Yte, y_scores)\n",
    "print ('Accuracy score: %.4f, roc AUC score: %.4f' % (accuracy, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "#print solution attributes\n",
    "solution_obj = mkl.solution\n",
    "\n",
    "weights = mkl.solution.weights\n",
    "print(len(weights))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QtKernel_x_AD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
